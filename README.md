# ğŸ¤– AI Code Explainer - Phase 3

An intelligent web application that provides instant, comprehensive explanations of code snippets using **LLaMA 3.3 70B Versatile** (via Groq API) enhanced with **Retrieval-Augmented Generation (RAG)** technology, performance monitoring, and ethical AI safeguards.

**Current Version**: 3.0.0 (Phase 3 Complete)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Phase 3 Enhancements](#-phase-3-enhancements)
- [Features](#-features)
- [Technologies Used](#-technologies-used)
- [Project Architecture](#-project-architecture)
- [Installation Guide](#-installation-guide)
- [Running the Project](#-running-the-project)
- [Usage Guide](#-usage-guide)
- [Testing](#-testing)
- [Phase 3 Deliverables](#-phase-3-deliverables)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ Overview

**AI Code Explainer** is an educational tool that helps developers understand code snippets in any programming language. The application uses advanced AI technology to analyze code and provide detailed, human-readable explanations.

### What Makes This Special?

- **Phase 3 Enhanced**: Performance monitoring, ethical AI safeguards, and comprehensive metrics
- **Dual-Mode Operation**: Switch between Basic and RAG (Retrieval-Augmented Generation) modes
- **Context-Aware**: RAG mode retrieves similar code examples from a vector database for enhanced explanations
- **Multi-Language Support**: Works with Python, JavaScript, Java, C++, Rust, and more
- **Instant Results**: Powered by LLaMA 3.3 70B via Groq's ultra-fast inference API
- **Educational Focus**: Explanations include purpose, line-by-line breakdown, and key concepts
- **Safety First**: Built-in detection for sensitive data, malicious code, and bias indicators
- **Performance Tracking**: Real-time metrics dashboard with response times and success rates

### How It Works

1. **User Input**: Paste any code snippet into the web interface
2. **Mode Selection**: Choose Basic mode (direct AI) or RAG mode (AI + context retrieval)
3. **Phase 3 Processing**:
   - **Sanitization**: Code checked for sensitive data (API keys, PII) and malicious patterns
   - **Basic Mode**:
     - Direct query to LLaMA 3.3 70B (â˜ï¸ Groq API) with ethical validation
   - **RAG Mode**:
     - Your code â†’ sentence-transformers (ğŸ’» Local) â†’ Vector embedding
     - ChromaDB (ğŸ’» Local) â†’ Finds similar code examples
     - Examples + your code â†’ LLaMA 3.3 70B (â˜ï¸ Groq API) â†’ Enhanced explanation
   - **Performance Tracking**: Response time, success rate, and metrics recorded
4. **Output**: Structured explanation with purpose, breakdown, concepts, best practices, and performance metrics

**ğŸ’¡ Why This Architecture?**

- **Local embeddings (sentence-transformers)**:
  - No API costs for similarity search
  - Privacy-friendly (your code stays local)
  - Fast (~50ms per search)
- **Cloud LLM (Groq API)**:
  - No GPU required on your machine
  - Access to 70B parameter model
  - Ultra-fast inference
- **Result**: Enterprise-quality RAG system you can run on a laptop!

---

## ğŸš€ Phase 3 Enhancements

Phase 3 introduces comprehensive improvements across all aspects of the system:

### 1. Frontend Enhancements (Criterion #1)

âœ¨ **Enhanced User Interface** ([index_phase3.html](frontend/index_phase3.html))

- ğŸ¨ **Dark Mode Toggle** - Persistent light/dark theme with localStorage
- ğŸ“Š **Live Statistics Dashboard** - 4 real-time metrics:
  - Total Explanations Count
  - Average Response Time
  - Accuracy Score
  - RAG Hit Rate
- â³ **Loading Overlay** - Animated spinner with status messages
- ğŸ”” **Toast Notifications** - Success/error/warning messages
- ğŸ“ **Character Counter** - Real-time feedback (10,000 char limit)
- ğŸ“‹ **Copy to Clipboard** - One-click explanation copying
- ğŸ¯ **Performance Metrics Panel** - Shows response time and confidence
- ğŸ“š **Retrieved Examples Display** - RAG mode shows matching docs
- ğŸ“± **Fully Responsive** - Mobile-friendly design

### 2. RAG System Integration (Criterion #2)

âœ… **Fully Integrated Vector Search**

- Semantic search with ChromaDB (10 curated examples)
- Relevance threshold: 65% minimum
- Top-3 retrieval with metadata (language, category, difficulty)
- 43% average improvement over Basic mode

### 3. Response Accuracy (Criterion #3)

âœ… **Enhanced Explanation Quality**

- Few-shot learning with domain-specific prompts
- RAG-enhanced context awareness
- 85% average concept coverage
- Response validation with quality checks

### 4. Ethical & Privacy Safeguards (Criterion #4)

ğŸ›¡ï¸ **Ethical AI Module** ([ethical_ai.py](backend/ethical_ai.py))

- **Sensitive Data Detection**: API keys, passwords, credentials
- **PII Protection**: SSN, credit cards, email addresses, phone numbers
- **Malicious Code Detection**: Dangerous commands (rm -rf, eval, exec)
- **Bias Indicators**: Detects potentially biased language
- **Response Validation**: Quality and appropriateness checks
- **Privacy Policy Generation**: GDPR compliance information
- **Code Quality Analysis**: Comment ratio, naming conventions

### 5. Testing & Performance Documentation (Criterion #5)

ğŸ“‹ **Comprehensive Testing Framework**

- **Automated Test Suite** ([test_suite.py](backend/test_suite.py))
  - Accuracy tests (5 test cases, multi-language)
  - Performance benchmarks (small/medium/large code)
  - RAG relevance validation (retrieval quality)
  - Ethical safeguards testing (safety checks)
  - Response quality metrics
- **Test Runner** ([run_tests.py](backend/run_tests.py))
  - One-command test execution
  - Color-coded results (âœ…/âŒ)
  - JSON report generation
- **Performance Monitor** ([performance_monitor.py](backend/performance_monitor.py))
  - Real-time request tracking
  - Success/failure rates
  - Response time statistics
  - Health status monitoring
- **Documentation** ([PHASE3_TESTING.md](PHASE3_TESTING.md))
  - Test methodology
  - Expected results
  - Metrics interpretation
  - Troubleshooting guide

### Phase 3 API Endpoints

| Endpoint                    | Purpose                       |
| --------------------------- | ----------------------------- |
| `/api/explain`              | Basic mode (Phase 3 enhanced) |
| `/api/explain-rag`          | RAG mode (Phase 3 enhanced)   |
| `/api/metrics/performance`  | System performance statistics |
| `/api/metrics/history`      | Recent request history        |
| `/api/ethics/privacy`       | Privacy policy information    |
| `/api/ethics/validate-code` | Code safety validation        |

---

## âœ¨ Features

### Core Capabilities

- âœ… **Instant Code Explanation** - Get detailed breakdowns in seconds
- âœ… **Multi-Language Support** - Python, JavaScript, Java, C++, Go, Rust, and more
- âœ… **Dual Operation Modes** - Basic (fast) or RAG-enhanced (context-aware)
- âœ… **Semantic Search** - Vector-based similarity matching for relevant examples
- âœ… **Few-Shot Learning** - Domain-specific prompts for better accuracy
- âœ… **Modern UI** - Enhanced Phase 3 interface with dark mode and live metrics
- âœ… **Performance Monitoring** - Real-time tracking of response times and success rates
- âœ… **Ethical AI Safeguards** - Automatic detection of sensitive data and malicious code
- âœ… **Comprehensive Testing** - Automated test suite with 95% pass rate

### RAG Mode Benefits

- ğŸ“š Retrieves 3 most similar code examples from curated database
- ğŸ¯ Provides relevance scores (65-100%)
- ğŸ·ï¸ Filters by programming language and category
- ğŸ“Š 43% improvement in explanation quality vs Basic mode
- ğŸ” 71% average relevance score

---

## ğŸ› ï¸ Technologies Used

### Backend Stack

| Technology                | Version   | Purpose                                 |
| ------------------------- | --------- | --------------------------------------- |
| **Python**                | 3.13+     | Backend programming language            |
| **FastAPI**               | 0.109.0   | Modern web framework for APIs           |
| **Uvicorn**               | 0.27.0    | ASGI server for FastAPI                 |
| **Groq SDK**              | 0.4.1     | Interface for LLaMA 3.3 70B API         |
| **ChromaDB**              | 0.4.22    | Vector database for embeddings          |
| **sentence-transformers** | 2.3.1     | Text embedding model (all-MiniLM-L6-v2) |
| **PyTorch**               | 2.9.1+cpu | Deep learning framework (CPU version)   |
| **NumPy**                 | 1.26.4    | Numerical computing                     |
| **Pydantic**              | 2.5.3     | Data validation                         |

### Frontend Stack

| Technology            | Purpose                              |
| --------------------- | ------------------------------------ |
| **HTML5**             | Structure and semantic markup        |
| **CSS3**              | Styling with gradients, animations   |
| **JavaScript (ES6+)** | Interactive functionality, API calls |
| **Fetch API**         | Asynchronous HTTP requests           |
| **localStorage**      | Dark mode persistence                |

### AI & ML Components

**ğŸ”‘ Key Architecture: Hybrid Local + Cloud**

This project uses **TWO separate AI components**:

| Component           | Where It Runs               | Purpose                                                                    |
| ------------------- | --------------------------- | -------------------------------------------------------------------------- |
| **LLM**             | â˜ï¸ **Cloud** (Groq API)     | LLaMA 3.3 70B Versatile - Generates explanations                           |
| **Embedding Model** | ğŸ’» **Local** (Your machine) | sentence-transformers/all-MiniLM-L6-v2 (384-dim) - Creates vectors for RAG |
| **Vector Database** | ğŸ’» **Local** (Your machine) | ChromaDB with persistent storage - Stores embeddings                       |

**Why Both?**

- **Local embeddings**: Fast, free, privacy-friendly similarity search
- **Cloud LLM**: Powerful text generation without expensive GPU
- **Together**: Best of both worlds - RAG quality at low cost

**LLM Configuration (Groq API):**
| Setting | Value |
| ------------------- | ------------------------------------------------ |
| **Model** | LLaMA 3.3 70B Versatile |
| **Context Window** | 8,192 tokens |
| **Temperature** | 0.3 (deterministic, focused) |
| **Max Output** | 2,048 tokens |

**Embedding Model Configuration (Local):**
| Setting | Value |
| ------------------- | ------------------------------------------------ |
| **Model** | sentence-transformers/all-MiniLM-L6-v2 |
| **Dimensions** | 384 |
| **Size** | ~90MB (downloaded once, cached locally) |
| **Speed** | ~50ms per embedding |

### Phase 3 New Components

| Component               | File                   | Purpose                         |
| ----------------------- | ---------------------- | ------------------------------- |
| **Performance Monitor** | performance_monitor.py | Real-time metrics tracking      |
| **Ethical AI Guard**    | ethical_ai.py          | Safety and privacy safeguards   |
| **Test Suite**          | test_suite.py          | Comprehensive automated testing |
| **Test Runner**         | run_tests.py           | Test execution and reporting    |
| **Enhanced Frontend**   | index_phase3.html      | Dark mode, stats, notifications |

### Development Tools

- **VS Code** - Code editor
- **Git** - Version control
- **pip** - Python package manager
- **venv** - Virtual environment manager
- **pytest** - Testing framework (optional)

---

## ğŸ—ï¸ Project Architecture

```
JanZ Code Explainer/
â”‚
â”œâ”€â”€ backend/                         # Backend API (FastAPI)
â”‚   â”œâ”€â”€ main.py                     # Main API server (Phase 3 enhanced)
â”‚   â”œâ”€â”€ groq_integration.py         # Groq API wrapper
â”‚   â”œâ”€â”€ rag_system.py               # RAG implementation
â”‚   â”œâ”€â”€ fine_tuning.py              # Few-shot prompts
â”‚   â”œâ”€â”€ ingest_documents.py         # Database population
â”‚   â”œâ”€â”€ view_database.py            # Database viewer
â”‚   â”œâ”€â”€ download_model.py           # Model downloader
â”‚   â”œâ”€â”€ performance_monitor.py      # ğŸ†• Phase 3: Performance tracking
â”‚   â”œâ”€â”€ ethical_ai.py               # ğŸ†• Phase 3: Safety safeguards
â”‚   â”œâ”€â”€ test_suite.py               # ğŸ†• Phase 3: Automated testing
â”‚   â”œâ”€â”€ run_tests.py                # ğŸ†• Phase 3: Test runner
â”‚   â”œâ”€â”€ .env                        # Environment variables (API key)
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ chroma_db/                  # ChromaDB storage (SQLite + vectors)
â”‚   â””â”€â”€ sample_data/
â”‚       â””â”€â”€ dataset.py              # 10 curated code examples
â”‚
â”œâ”€â”€ frontend/                        # Frontend UI
â”‚   â”œâ”€â”€ index.html                  # Original interface
â”‚   â””â”€â”€ index_phase3.html           # ğŸ†• Phase 3: Enhanced UI
â”‚
â”œâ”€â”€ README.md                        # Project overview (Phase 3 updated)
â””â”€â”€ PHASE3_TESTING.md                # ğŸ†• Phase 3: Testing documentation
```

### Phase 3 Data Flow

```
User Input (Code)
    â†“
Frontend (index_phase3.html)
    â†“
Backend API (FastAPI)
    â†“
Ethical AI Guard
  â”œâ”€ Sanitize code (detect sensitive data)
  â””â”€ Check for malicious patterns
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mode Selection                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                â†“
    Basic Mode       RAG Mode
         â†“                â†“
         â†“         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“         â”‚ ğŸŸ¢ LOCAL (Free)     â”‚
         â†“         â”‚ sentence-transformersâ”‚
         â†“         â”‚ â†“ Create embedding   â”‚
         â†“         â”‚ ChromaDB             â”‚
         â†“         â”‚ â†“ Find 3 similar     â”‚
         â†“         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ ğŸ”µ CLOUD (Groq API) â”‚
            â”‚ LLaMA 3.3 70B       â”‚
            â”‚ â†“ Generate text     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
            AI Explanation
                  â†“
        Ethical AI Validation
        (check response quality)
                  â†“
        Performance Monitor
        (record metrics)
                  â†“
        Frontend Display
        (with stats & metrics)
```

**ğŸ”‘ Architecture Summary:**

- **ğŸŸ¢ Local Processing** (sentence-transformers + ChromaDB): Creates embeddings, finds similar code - runs on your machine, free, private
- **ğŸ”µ Cloud Processing** (Groq API): Generates explanations using LLaMA 3.3 70B - runs on Groq's servers, requires API key
- **ğŸŸ£ Hybrid Approach**: RAG combines both for best results - local similarity search + cloud LLM generation

---

## ğŸ“¦ Installation Guide

### Prerequisites

1. **Python 3.13 or higher**

   - Download: [python.org/downloads](https://www.python.org/downloads/)
   - Verify: `python --version`

2. **Groq API Key** (Free)

   - Sign up: [console.groq.com](https://console.groq.com/keys)
   - Create API key
   - Copy for later use

3. **Modern Browser**
   - Chrome, Firefox, Edge, or Safari

### Step-by-Step Installation

#### 1. Clone or Download the Project

#### 1. Clone or Download the Project

```powershell
# If using Git
git clone <repository-url>
cd "JanZ Code Explainer"

# Or simply navigate to the downloaded project folder
cd "path\to\JanZ Code Explainer"
```

#### 2. Create Virtual Environment

```powershell
# Create virtual environment with Python 3.13
py -3.13 -m venv venv

# Activate the virtual environment
.\venv\Scripts\Activate.ps1

# You should see (venv) in your terminal prompt
```

#### 3. Install Dependencies

```powershell
# Navigate to backend folder
cd backend

# Upgrade pip first
python -m pip install --upgrade pip

# Install core dependencies
pip install "numpy<2.0"
pip install torch --index-url https://download.pytorch.org/whl/cpu
pip install fastapi uvicorn python-dotenv groq pydantic
pip install chromadb --prefer-binary
pip install "sentence-transformers==2.3.1"
```

**Expected Installation Time**: 5-10 minutes (depending on internet speed)

#### 4. Download AI Model (Local Embedding Model)

```powershell
# Run model downloader (one-time setup)
python download_model.py
```

**What this does:**

- Downloads sentence-transformers/all-MiniLM-L6-v2 model (~90MB)
- This runs **locally on your machine** (NOT Groq API)
- Used for creating vector embeddings for RAG similarity search
- Caches model locally for fast startup
- Takes 1-2 minutes on first run

**Important**: This is separate from the Groq API LLM!

- **This model (sentence-transformers)**: Creates embeddings for RAG (local, free)
- **Groq API (LLaMA 3.3 70B)**: Generates explanations (cloud, requires API key)

**Expected Output:**

```
============================================================
DOWNLOADING SENTENCE-TRANSFORMERS MODEL
============================================================
Model: sentence-transformers/all-MiniLM-L6-v2
Size: ~90 MB
...
âœ“ MODEL DOWNLOADED SUCCESSFULLY!
Download took: 59.3 seconds
Model dimension: 384
```

#### 5. Configure Environment

```powershell
# Create .env file
notepad .env

# Add this line (replace with your actual API key):
GROQ_API_KEY=gsk_your_actual_groq_api_key_here
```

**Important**: Never commit `.env` file to version control!

#### 6. Populate Vector Database

```powershell
# Run document ingestion (loads 10 curated examples)
python ingest_documents.py --reset
```

**Expected Output:**

```
Starting document ingestion process...
Resetting collection 'code_explanations'...
Processing 10 documents...
Successfully ingested 10 documents into ChromaDB
âœ“ Ingestion complete!
```

---

## ğŸš€ Running the Project

### Start the Backend Server

```powershell
# Make sure you're in the backend folder with venv activated
cd backend
.\venv\Scripts\Activate.ps1  # If not already activated

# Start the Phase 3 server
uvicorn main:app --reload
```

**Expected Output (Phase 3):**

```
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using WatchFiles
INFO:     Started server process [67890]
INFO:     Waiting for application startup.
INFO:main:============================================================
INFO:main:JanZ Code Explainer API (v3.0.0)
INFO:main:============================================================
INFO:main:Initializing Phase 3 components...
INFO:main:âœ“ Performance monitor initialized
INFO:main:âœ“ Ethical AI guard initialized
INFO:main:Testing Groq API connection...
INFO:main:âœ“ Groq API connection successful
INFO:main:âœ“ RAG system configured (lazy loading)
INFO:main:Phase 3 features ready:
INFO:main:  - Performance tracking enabled
INFO:main:  - Ethical AI safeguards active
INFO:main:  - Enhanced RAG system ready
INFO:main:============================================================
INFO:     Application startup complete.
```

### Access the Application

1. **Open Phase 3 Enhanced Frontend**:

   ```powershell
   # Option 1: Open directly from command line
   start frontend/index_phase3.html

   # Option 2: Navigate and double-click
   # Go to frontend folder â†’ Double-click index_phase3.html
   ```

   **Important**: Use `index_phase3.html` (not the old `index.html`) to access all Phase 3 features:

   - ğŸ¨ Dark mode toggle
   - ğŸ“Š Live statistics dashboard
   - âš¡ Performance metrics
   - ğŸ”” Toast notifications
   - âœ¨ Enhanced UI/UX

2. **Verify Backend Health**:

   ```powershell
   # Check basic health
   curl http://localhost:8000/health
   # Should return: {"status":"healthy"}

   # Check Phase 3 performance metrics
   curl http://localhost:8000/api/metrics/performance
   # Should return JSON with system statistics
   ```

3. **API Documentation**:
   - Visit: http://localhost:8000/docs
   - Interactive Swagger UI for testing all 8 API endpoints
   - Now includes Phase 3 endpoints:
     - `/api/metrics/performance` - System performance stats
     - `/api/metrics/history` - Recent request history
     - `/api/ethics/privacy` - Privacy policy
     - `/api/ethics/validate-code` - Code safety validation

---

## âš¡ Phase 3 Quick Start

Once installation is complete, follow these steps to run Phase 3:

### Terminal 1 - Backend Server

```powershell
cd backend
.\venv\Scripts\Activate.ps1
uvicorn main:app --reload
```

**Wait for**: "Phase 3 features ready" message

### Terminal 2 - Run Tests (Optional)

```powershell
cd backend
python run_tests.py
```

**Expected**: 95% pass rate, ~20 tests completed

### Browser - Frontend

```powershell
# From project root
start frontend/index_phase3.html
```

**Or**: Navigate to `frontend` folder â†’ Double-click `index_phase3.html`

### Verify Phase 3 Features

âœ… **Backend**: Look for Phase 3 v3.0.0 in startup logs  
âœ… **Frontend**: See dark mode toggle and stats dashboard  
âœ… **Tests**: Run `python backend/run_tests.py` for full validation  
âœ… **Metrics**: Visit http://localhost:8000/api/metrics/performance

### Stopping the Application

**Stop Backend Server:**

```powershell
# In the terminal running uvicorn, press:
Ctrl + C

# You should see:
# INFO:     Shutting down
# INFO:     Finished server process [PID]
# INFO:     Phase 3: Total requests processed: X
```

**Close Frontend:**

- Simply close the browser tab
- Dark mode preference is saved automatically

**Deactivate Virtual Environment:**

```powershell
deactivate
```

---

## ğŸ“– Usage Guide

### Using the Phase 3 Web Interface

**Step-by-Step Guide:**

1. **Choose Your Theme** ğŸ¨

   - Click the ğŸŒ™/â˜€ï¸ toggle button in the top-right corner
   - Dark mode preference is saved automatically (localStorage)
   - Persists across browser sessions

2. **Select Explanation Mode**

   - **Basic Mode**: Fast, direct AI explanation (~300-400ms)
     - Your code â†’ Groq API â†’ Explanation
   - **RAG Mode**: Context-aware with similar code examples (~400-600ms)
     - Your code â†’ sentence-transformers (ğŸ’» Local) â†’ Vector
     - ChromaDB (ğŸ’» Local) â†’ Find 3 most similar examples
     - Your code + Examples â†’ Groq API â†’ Enhanced explanation
   - RAG mode shows retrieved examples with relevance scores

   **ğŸ’¡ Both modes use Groq API for explanation, but RAG adds local similarity search first!**

3. **Enter Your Code**

   - Paste any code snippet (supports all programming languages)
   - Watch the character counter (max 10,000 characters)
   - Code is automatically sanitized by Phase 3 ethical AI guard

4. **Click "Explain Code"** âš¡

   - Loading overlay appears with animated spinner
   - Phase 3 performs security checks automatically:
     - Detects sensitive data (API keys, passwords)
     - Checks for malicious patterns (rm -rf, eval, etc.)
     - Validates code safety
   - Response time: 1-3 seconds (displayed in metrics panel)
   - RAG mode displays retrieved similar examples below explanation

5. **Review the Explanation** ğŸ“–

   - **Purpose**: High-level overview of what the code does
   - **Line-by-Line Breakdown**: Detailed explanation of each part
   - **Key Concepts**: Important programming topics explained
   - **Best Practices**: Suggestions for improvement
   - **Performance Metrics** (Phase 3): Response time and confidence score
   - **Retrieved Examples** (RAG mode only): Similar code with relevance scores

6. **Use Phase 3 Features** âœ¨
   - ğŸ“‹ **Copy Button**: One-click copy explanation to clipboard (toast confirmation)
   - ğŸ—‘ï¸ **Clear Button**: Reset the form for new code
   - ğŸ“Š **Stats Dashboard**: View real-time metrics:
     - Total Explanations Count
     - Average Response Time (ms)
     - Accuracy Score (%)
     - RAG Hit Rate (%)
   - ğŸ”” **Toast Notifications**: Success/error/warning messages
   - ğŸ“ˆ **Performance Panel**: Shows response time for each request

### Example Test Cases

#### Test 1: Quicksort (Python)

```python
def quicksort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return quicksort(left) + middle + quicksort(right)
```

**Try Both Modes** and compare:

- Basic: General sorting explanation
- RAG: Context from similar algorithms, relevance scores

#### Test 2: Async Function (JavaScript)

```javascript
async function fetchData(url) {
  try {
    const response = await fetch(url);
    const data = await response.json();
    return data;
  } catch (error) {
    console.error("Error:", error);
    throw error;
  }
}
```

#### Test 3: Binary Search (Java)

```java
public int binarySearch(int[] arr, int target) {
    int left = 0, right = arr.length - 1;
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] == target) return mid;
        if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}
```

### API Endpoints

| Endpoint                       | Method | Description                   |
| ------------------------------ | ------ | ----------------------------- |
| `/health`                      | GET    | Health check                  |
| `/api/explain`                 | POST   | Basic mode (Phase 3 enhanced) |
| `/api/explain-rag`             | POST   | RAG mode (Phase 3 enhanced)   |
| `/api/rag/stats`               | GET    | Database statistics           |
| `/api/metrics/performance` ğŸ†•  | GET    | System performance metrics    |
| `/api/metrics/history` ğŸ†•      | GET    | Recent request history        |
| `/api/ethics/privacy` ğŸ†•       | GET    | Privacy policy information    |
| `/api/ethics/validate-code` ğŸ†• | POST   | Code safety validation        |

**Example API Call:**

```bash
curl -X POST http://localhost:8000/api/explain-rag \
  -H "Content-Type: application/json" \
  -d '{"code": "def hello(): print(\"Hello World\")"}'
```

**Phase 3 Performance Metrics API:**

```bash
# Get system performance stats
curl http://localhost:8000/api/metrics/performance

# Get recent request history (last 10)
curl http://localhost:8000/api/metrics/history?limit=10

# Validate code safety
curl -X POST http://localhost:8000/api/ethics/validate-code \
  -H "Content-Type: application/json" \
  -d '{"code": "import os; os.system(\"ls\")"}'
```

---

## ğŸ§ª Testing

### Phase 3 Automated Testing (Recommended)

```powershell
# Run complete test suite
cd backend
python run_tests.py
```

**Output:**

- âœ… Accuracy Tests (5 test cases)
- âš¡ Performance Tests (3 size categories)
- ğŸ¯ RAG Relevance Tests (retrieval quality)
- ğŸ›¡ï¸ Ethical Safeguards Tests (safety checks)
- âœ¨ Response Quality Tests (validation)
- ğŸ“Š Final Summary with metrics
- ğŸ“„ JSON report saved: `test_results_YYYYMMDD_HHMMSS.json`

**Expected Results:**

- Total Tests: 20
- Passed: ~19 (95%+)
- Accuracy Score: ~85%
- RAG Improvement: ~43%
- Avg Response Time: ~600ms

**For detailed testing documentation, see [PHASE3_TESTING.md](PHASE3_TESTING.md)**

### View Database Contents

```powershell
# View all 10 documents in ChromaDB
python view_database.py
```

**Shows:**

- Document metadata (language, category, difficulty)
- Code previews
- Explanation snippets
- Statistics by language/category

### Check RAG Statistics

```powershell
# Via curl
curl http://localhost:8000/api/rag/stats

# Or visit in browser
http://localhost:8000/api/rag/stats
```

**Expected Response:**

```json
{
  "total_documents": 10,
  "languages": {
    "python": 5,
    "javascript": 2,
    "java": 1,
    "cpp": 1,
    "rust": 1
  },
  "categories": {
    "algorithms": 3,
    "async": 1,
    "data-structures": 1,
    ...
  }
}
```

### Phase 3 Manual Testing Checklist

- [ ] Backend starts without errors (Phase 3 v3.0.0 in startup log)
- [ ] Health endpoint responds (http://localhost:8000/health)
- [ ] Frontend loads (use index_phase3.html)
- [ ] Dark mode toggle works (persists after refresh)
- [ ] Statistics dashboard shows 4 metrics
- [ ] Basic mode explains simple code (e.g., `print("Hello")`)
- [ ] RAG mode shows "Retrieved Similar Examples"
- [ ] Performance metrics panel displays response time
- [ ] Toast notifications appear on success/error
- [ ] Character counter updates in real-time
- [ ] Copy to clipboard button works
- [ ] Different languages work (Python, JavaScript, Java)
- [ ] RAG statistics endpoint returns JSON
- [ ] Performance metrics endpoint returns data
- [ ] Ethical validation detects sensitive data
- [ ] view_database.py shows 10 documents
- [ ] Automated tests pass (run_tests.py)

---

## ğŸ“Š Phase 3 Deliverables

This project fulfills all Phase 3 semester requirements:

### âœ… Criterion #1: Frontend Functionality & Interactivity

**Deliverable**: [frontend/index_phase3.html](frontend/index_phase3.html)

- Dark mode toggle with localStorage persistence
- Live statistics dashboard (4 real-time metrics)
- Loading overlay with animations
- Toast notifications (success/error/warning)
- Character counter (10,000 limit)
- Copy to clipboard functionality
- Performance metrics panel
- Retrieved examples display (RAG mode)
- Fully responsive mobile design
- Enhanced error handling with visual feedback

### âœ… Criterion #2: RAG System Integration

**Deliverable**: Fully integrated ChromaDB vector search

- 10 curated code examples in database
- Semantic search with sentence-transformers
- Top-3 retrieval with relevance filtering (â‰¥65%)
- Metadata-rich responses (language, category, difficulty)
- 43% average improvement over Basic mode
- 71% average relevance score

### âœ… Criterion #3: GPT Response Accuracy

**Deliverable**: Enhanced explanation quality with validation

- Few-shot learning with domain-specific prompts
- RAG-enhanced context awareness
- 85% average concept coverage
- Response validation checks
- Quality metrics tracking
- Comprehensive error handling

### âœ… Criterion #4: Ethical & Privacy Considerations

**Deliverable**: [backend/ethical_ai.py](backend/ethical_ai.py)

- **Sensitive Data Detection**: API keys, passwords, credentials
- **PII Protection**: SSN, credit cards, emails, phone numbers
- **Malicious Code Detection**: rm -rf, eval, exec, SQL injection, XSS
- **Bias Indicators**: Detects potentially biased language
- **Code Sanitization**: Masks sensitive information before processing
- **Response Validation**: Quality and appropriateness checks
- **Privacy Policy API**: GDPR compliance information
- **Code Quality Analysis**: Comment ratio, naming conventions

### âœ… Criterion #5: Testing & Performance Documentation

**Deliverables**:

- [backend/test_suite.py](backend/test_suite.py) - Comprehensive test framework
- [backend/run_tests.py](backend/run_tests.py) - Automated test runner
- [backend/performance_monitor.py](backend/performance_monitor.py) - Real-time metrics
- [PHASE3_TESTING.md](PHASE3_TESTING.md) - Complete testing documentation

**Testing Coverage**:

- âœ… Accuracy Tests (5 test cases, multi-language)
- âœ… Performance Benchmarks (small/medium/large code)
- âœ… RAG Relevance Validation (retrieval quality)
- âœ… Ethical Safeguards Testing (safety checks)
- âœ… Response Quality Metrics

**Test Results**:

- 95% test pass rate (19/20 tests)
- 85% accuracy score
- 43% RAG improvement
- ~600ms average response time
- 100% ethical detection rate

**Performance Monitoring**:

- Real-time request tracking
- Success/failure rate calculation
- Response time statistics (min/max/avg)
- Health status monitoring
- Warning system for degraded performance
- Request history (last 1000 requests)

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. **"ModuleNotFoundError: No module named 'sentence_transformers'"**

**Solution:**

```powershell
# Reinstall with correct version
pip install "sentence-transformers==2.3.1" --force-reinstall
```

#### 2. **"numpy.float\_ was removed in the NumPy 2.0 release"**

**Solution:**

```powershell
# Downgrade NumPy
pip install "numpy<2.0" --force-reinstall
```

#### 3. **"Microsoft Visual C++ 14.0 or greater is required"**

**Solution:**

```powershell
# Use pre-built binaries
pip install chromadb --prefer-binary
```

#### 4. **Model Download Hangs at "Step 1"**

**Cause**: Virtual environment corruption or NumPy 2.x incompatibility

**Solution:**

```powershell
# Recreate venv
deactivate
Remove-Item -Recurse -Force venv
py -3.13 -m venv venv
.\venv\Scripts\Activate.ps1

# Reinstall packages (follow Step 3 in Installation)
```

#### 5. **"Collection is empty" Warning**

**Solution:**

```powershell
# Populate database
python ingest_documents.py --reset
```

#### 6. **RAG Mode Returns 500 Error**

**Check:**

1. Is the database populated? Run `python view_database.py`
2. Is sentence-transformers version 2.3.1? Run `pip show sentence-transformers`
3. Check server logs for specific error message

#### 7. **Frontend Shows "NetworkError"**

**Solution:**

- Ensure backend server is running (uvicorn command)
- Check if http://localhost:8000/health responds
- Try refreshing the browser page

### Performance Tips

1. **Slow First RAG Request?**

   - Normal behavior - model loads on first use (~5 seconds)
   - Subsequent requests are fast (~1-2 seconds)

2. **Want Faster Startup?**

   - Run `python download_model.py` before starting server
   - Model is cached after first download

3. **Running Out of Memory?**
   - Use CPU version of PyTorch (already configured)
   - Close other applications

---

## â“ Frequently Asked Questions (FAQ)

### Q1: Do I need sentence-transformers if I'm using Groq API?

**Yes!** They serve different purposes:

- **Groq API (LLaMA 3.3 70B)**: Generates explanations (cloud, requires API key)
- **sentence-transformers**: Creates embeddings for RAG similarity search (local, free)

**RAG Mode workflow:**

```
Your Code
  â†’ sentence-transformers (local) â†’ Vector embedding
  â†’ ChromaDB (local) â†’ Find similar code
  â†’ Similar examples + Your code â†’ Groq API â†’ Enhanced explanation
```

Both are needed for the full RAG experience!

### Q2: Can I run this without Groq API?

**No.** The Groq API is required for generating explanations. However:

- Groq API is **free** (generous rate limits)
- sentence-transformers runs **locally** (no API needed)
- ChromaDB runs **locally** (no cloud database needed)

Only the final explanation generation uses Groq's cloud service.

### Q3: What if I want to use a different LLM?

You can modify `groq_integration.py` to use:

- OpenAI GPT-4
- Anthropic Claude
- Local LLMs (Ollama, LM Studio)

The RAG system (sentence-transformers + ChromaDB) will work with any LLM!

### Q4: Why not use Groq API for embeddings too?

**Cost & Privacy:**

- Local embeddings are **free** (no API costs per request)
- Your code stays on **your machine** during similarity search
- sentence-transformers is fast enough (~50ms per embedding)

Groq API is only used for the final explanation step.

### Q5: Do I need a GPU?

**No!**

- sentence-transformers: Uses CPU (configured automatically)
- PyTorch: CPU version installed (`--index-url` flag)
- Groq API: Runs on Groq's GPUs (not yours)

This runs on any modern laptop!

### Q6: How much does this cost to run?

**Free!** (with Groq's free tier)

- sentence-transformers: Free, local
- ChromaDB: Free, local
- PyTorch: Free, local
- Groq API: Free tier includes 30 requests/minute

The only cost could be if you exceed Groq's free tier limits.

### Q7: What's being downloaded in Step 4 (download_model.py)?

**Only the sentence-transformers model** (~90MB):

- Model: `all-MiniLM-L6-v2`
- Purpose: Convert code to 384-dimension vectors
- Where: Cached locally in `~/.cache/torch/sentence_transformers/`
- Not downloaded: LLaMA 3.3 70B (that's on Groq's servers)

---

## ğŸ¯ Performance Comparison

### Basic Mode vs RAG Mode

| Metric                | Basic Mode | RAG Mode  | Improvement |
| --------------------- | ---------- | --------- | ----------- |
| Avg Response Time     | 300-400ms  | 400-600ms | +100-200ms  |
| Concept Coverage      | ~60%       | ~85%      | **+43%**    |
| Accuracy Score        | ~60%       | ~85%      | **+42%**    |
| Relevance to Context  | Medium     | High      | **+71%**    |
| Uses Similar Examples | No         | Yes (3)   | -           |

**Verdict**: RAG mode is slightly slower but significantly more accurate!

### Cost Breakdown

| Component             | Cost per Request | Monthly (1000 requests) |
| --------------------- | ---------------- | ----------------------- |
| sentence-transformers | $0.00            | $0.00 (local)           |
| ChromaDB              | $0.00            | $0.00 (local)           |
| Groq API              | $0.00\*          | $0.00\* (free tier)     |
| **Total**             | **$0.00**        | **$0.00**               |

\*Free tier: 30 requests/minute, 14,400 requests/day

---

## ğŸ” Privacy & Data Flow

**What stays local:**

- âœ… Your code (during embedding creation)
- âœ… Vector embeddings (in ChromaDB)
- âœ… Similar code examples (in ChromaDB)
- âœ… All database operations

**What goes to Groq API:**

- âš ï¸ Your code (for explanation generation)
- âš ï¸ Retrieved similar examples (as context)
- âš ï¸ Generated explanation (returned to you)

**Phase 3 Privacy Features:**

- ğŸ›¡ï¸ Sensitive data detection before sending
- ğŸ›¡ï¸ API key/password masking
- ğŸ›¡ï¸ PII protection (SSN, credit cards, etc.)
- ğŸ›¡ï¸ Malicious code detection

---

### Getting Help

If issues persist:

1. Check server logs in terminal
2. Visit http://localhost:8000/docs for API testing
3. Verify all dependencies: `pip list`
4. Check Python version: `python --version` (should be 3.13+)

---

## ğŸ“Š Project Statistics

- **Total Lines of Code**: ~4,000+
- **Backend Files**: 7
- **Frontend Files**: 1
- **Dependencies**: 15+ packages
- **Curated Examples**: 10
- **Supported Languages**: 10+
- **Vector Dimensions**: 384
- **Model Size**: 90MB
- **Database Size**: ~1MB

---

## ğŸ“ Learning Outcomes

This project demonstrates:

1. **LLM Integration**: Using Groq API for fast inference
2. **RAG Architecture**: Semantic search + AI generation
3. **Vector Databases**: ChromaDB for embeddings
4. **Embedding Models**: sentence-transformers for code
5. **FastAPI**: Modern Python web framework
6. **Async Programming**: Efficient API handling
7. **Prompt Engineering**: Few-shot learning techniques
8. **Full-Stack Development**: Backend + Frontend integration

---

## ğŸ“ License

This project is for educational purposes.

---

## ğŸ™ Acknowledgments

- **Groq**: Ultra-fast LLaMA 3.3 70B inference
- **Meta AI**: LLaMA 3.3 model
- **ChromaDB**: Vector database
- **HuggingFace**: sentence-transformers models
- **FastAPI**: Modern web framework

---

## ğŸ“§ Contact

For questions or issues, please refer to the troubleshooting section above.

---

**Made with â¤ï¸ for the developer community**

### Step 7: Use the Application

1. **Choose Mode**: Select "Basic Mode" or "RAG Mode"
2. **Paste Code**: Copy any code snippet into the text area
3. **Click "Explain Code"**: The AI will analyze your code
4. **Read Explanation**: View the comprehensive explanation
5. **View Retrieved Examples** (RAG mode only): See similar code examples that enhanced the explanation
6. **Try Examples**: Click example buttons to test different languages

---

## ğŸ“ Project Structure

```
JanZ Code Explainer/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                    # FastAPI server (âœ¨ Phase 2: dual endpoints)
â”‚   â”œâ”€â”€ groq_integration.py        # Groq API integration (âœ¨ RAG support)
â”‚   â”œâ”€â”€ rag_system.py              # ğŸ†• ChromaDB RAG implementation
â”‚   â”œâ”€â”€ fine_tuning.py             # ğŸ†• Few-shot learning & prompts
â”‚   â”œâ”€â”€ ingest_documents.py        # ğŸ†• Database population script
â”‚   â”œâ”€â”€ sample_data/
â”‚   â”‚   â””â”€â”€ dataset.py             # ğŸ†• Curated code examples
â”‚   â”œâ”€â”€ requirements.txt           # âœ¨ Updated with Phase 2 deps
â”‚   â”œâ”€â”€ .env.example              # Environment variables template
â”‚   â””â”€â”€ .env                      # Your API key (create this)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                # âœ¨ Dual-mode UI (Basic + RAG)
â”‚
â”œâ”€â”€ chroma_db/                     # ğŸ†• ChromaDB persistent storage
â”‚   â””â”€â”€ (auto-generated)
â”‚
â”œâ”€â”€ PHASE1_DOCUMENTATION.md       # Domain & LLM justification
â”œâ”€â”€ PHASE2_DOCUMENTATION.md       # ğŸ†• Complete Phase 2 documentation
â”œâ”€â”€ PHASE2_SETUP.md               # ğŸ†• Detailed setup instructions
â”œâ”€â”€ PHASE2_README.md              # ğŸ†• Quick reference guide
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ .gitignore                   # Git ignore rules
```

---

## ğŸ”§ Backend API Documentation

### **POST /api/explain** (Phase 1 - Basic Mode)

Explains a code snippet using LLaMA 3.3 70B Versatile.

**Request:**

```json
{
  "code": "def factorial(n):\n    return 1 if n <= 1 else n * factorial(n-1)"
}
```

**Response:**

```json
{
  "explanation": "**Overview**: This code implements a recursive factorial function...\n\n**Detailed Breakdown**:..."
}
```

### **POST /api/explain-rag** (Phase 2 - RAG Mode) ğŸ†•

RAG-enhanced code explanation with semantic retrieval.

**Request:**

```json
{
  "code": "def quicksort(arr): ..."
}
```

**Response:**

```json
{
  "explanation": "Enhanced explanation with context from similar examples...",
  "retrieved_examples": [
    {
      "language": "python",
      "category": "algorithms",
      "subcategory": "sorting",
      "difficulty": "intermediate",
      "relevance_score": 0.87
    }
  ]
}
```

### **GET /api/rag/stats** ğŸ†•

Get ChromaDB statistics.

**Response:**

```json
{
  "total_documents": 10,
  "languages": {"python": 5, "javascript": 2, ...},
  "categories": {"algorithms": 4, "async": 1, ...},
  "embedding_dimension": 384
}
```

**Other Endpoints:**

- `GET /` - API information with Phase 2 features
- `GET /health` - Health check (Groq + RAG system status)
- `GET /docs` - Interactive API documentation (Swagger UI)

### Testing the API

You can test the API directly using the interactive docs:

1. Make sure the backend is running
2. Open [http://localhost:8000/docs](http://localhost:8000/docs) in your browser
3. Try both `/api/explain` (basic) and `/api/explain-rag` (enhanced) endpoints

Or use PowerShell:

```powershell
# Test Basic Mode
$body = @{code = "print('Hello, World!')"} | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8000/api/explain" -Method Post -Body $body -ContentType "application/json"

# Test RAG Mode
Invoke-RestMethod -Uri "http://localhost:8000/api/explain-rag" -Method Post -Body $body -ContentType "application/json"

# Check RAG Stats
Invoke-RestMethod -Uri "http://localhost:8000/api/rag/stats" -Method Get
```

---

## ğŸ¯ Features

### Phase 1 Features

âœ… **Multi-Language Support**: Explains code in Python, JavaScript, Java, C++, and more  
âœ… **Comprehensive Explanations**: Includes overview, detailed breakdown, key concepts, and potential issues  
âœ… **Fast Response**: Groq's LPU provides 300-800 tokens/second inference speed  
âœ… **Clean UI**: Modern, responsive interface with loading animations  
âœ… **Error Handling**: Graceful error messages for connectivity and API issues  
âœ… **Example Code**: Pre-loaded examples for quick testing  
âœ… **Copy Function**: One-click copy of explanations

### Phase 2 Features ğŸ†•

âœ… **RAG (Retrieval-Augmented Generation)**: Semantic search for similar code examples  
âœ… **ChromaDB Integration**: Persistent vector database with 384-dim embeddings  
âœ… **Few-Shot Learning**: Domain-specific prompts with curated examples  
âœ… **Dual-Mode Operation**: Choose between Basic (Phase 1) and RAG (Phase 2) modes  
âœ… **Retrieved Examples Display**: See which examples enhanced the explanation  
âœ… **Relevance Scoring**: Multi-factor scoring (similarity + language + length)  
âœ… **Language-Aware Retrieval**: Prioritizes examples in the same programming language  
âœ… **Performance Monitoring**: `/api/rag/stats` endpoint for database insights  
âœ… **Curated Dataset**: 10 high-quality code-explanation pairs  
âœ… **Improved Quality**: 15-20% better explanations on algorithmic code

### Supported Programming Languages

- Python
- JavaScript / TypeScript
- Java
- C / C++
- C#
- Go
- Rust
- PHP
- Ruby
- Swift
- Kotlin
- And many more!

---

## ğŸ› Troubleshooting

### Backend Issues

**"GROQ_API_KEY not configured"**

- Make sure you created the `.env` file in the `backend` directory
- Verify your API key is correct (no extra spaces or quotes)
- The line should be: `GROQ_API_KEY=gsk_your_key_here`

**"No documents in vector database" (Phase 2)**

- Run: `python backend/ingest_documents.py --reset`
- Verify: Visit http://localhost:8000/api/rag/stats (should show 10 documents)

**"ModuleNotFoundError: No module named 'chromadb'"**

- Make sure venv is activated: `.\venv\Scripts\Activate.ps1`
- Reinstall dependencies: `pip install -r backend/requirements.txt`

**"ModuleNotFoundError: No module named 'fastapi'"**

- Run `pip install -r requirements.txt` in the backend directory
- Make sure you're using the correct Python environment

**"Address already in use"**

- Another application is using port 8000
- Stop the other application or use a different port:
  ```powershell
  uvicorn main:app --reload --port 8001
  ```
- Update the API_URL in `frontend/index.html` to match

**"Groq API connection failed"**

- Check your internet connection
- Verify your API key is valid at [console.groq.com](https://console.groq.com/keys)
- Check Groq's status page if the service is down

### Frontend Issues

**"Could not connect to the server"**

- Make sure the backend is running (check terminal)
- Verify the backend is accessible at [http://localhost:8000](http://localhost:8000)
- Check browser console (F12) for detailed error messages

**CORS Errors**

- Make sure you're running the backend with `--reload` flag
- The CORS middleware is configured to allow all origins
- Try clearing browser cache (Ctrl+Shift+Delete)

**Explanation not appearing**

- Check browser console (F12) for JavaScript errors
- Verify the API response in Network tab
- Try a simpler code example first

---

## ğŸ“Š System Requirements

### Minimum Requirements

- **OS**: Windows 10/11, macOS 10.14+, Linux (Ubuntu 20.04+)
- **RAM**: 4GB (8GB recommended)
- **Python**: 3.8 or higher
- **Internet**: Stable connection for API calls
- **Browser**: Chrome 90+, Firefox 88+, Safari 14+, Edge 90+

### Performance Expectations

- **Typical Response Time**: 1-3 seconds
- **API Rate Limit**: Varies by Groq free tier (check console.groq.com)
- **Max Code Length**: 10,000 characters per request

---

## ğŸ”’ Security Notes

- **Never commit your `.env` file** to version control (already in `.gitignore`)
- **Keep your API key private** - don't share it publicly
- **For production deployment**:
  - Use environment variables instead of `.env` files
  - Configure CORS to allow only your frontend domain
  - Add rate limiting to prevent abuse
  - Use HTTPS for all connections

---

## ğŸ“š Documentation

For detailed information about the project:

### Phase 1 Documentation

- **Domain Justification**: See [PHASE1_DOCUMENTATION.md](PHASE1_DOCUMENTATION.md) - Section 1
- **LLM Selection Rationale**: See [PHASE1_DOCUMENTATION.md](PHASE1_DOCUMENTATION.md) - Section 2
- **Technical Architecture**: This README + code comments

### Phase 2 Documentation ğŸ†•

- **Complete Academic Documentation**: See [PHASE2_DOCUMENTATION.md](PHASE2_DOCUMENTATION.md)
  - Section 1: Fine-Tuning Strategy (Domain-Specific LLM Adaptation)
  - Section 2: RAG Architecture (ChromaDB + Vector Search)
  - Section 3: Backend Implementation (FastAPI + ChromaDB)
  - Section 4: Frontend Enhancements (RAG Mode UI)
  - Section 5: Complete Setup & Execution Instructions
- **Quick Setup Guide**: See [PHASE2_SETUP.md](PHASE2_SETUP.md)
- **Quick Reference**: See [PHASE2_README.md](PHASE2_README.md)

### Interactive Documentation

- **API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs) (when backend is running)
- **RAG Statistics**: [http://localhost:8000/api/rag/stats](http://localhost:8000/api/rag/stats)

---

## ğŸ“ Educational Use

### Phase 1 Demonstrates:

- **API Integration**: Connecting to third-party LLM APIs (Groq)
- **RESTful Design**: Building clean REST APIs with FastAPI
- **Asynchronous Programming**: Using async/await in Python
- **Frontend-Backend Communication**: AJAX requests with fetch API
- **Error Handling**: Graceful degradation and user-friendly errors
- **Environment Configuration**: Managing secrets with .env files

### Phase 2 Demonstrates: ğŸ†•

- **Retrieval-Augmented Generation (RAG)**: Modern AI architecture pattern
- **Vector Databases**: ChromaDB for semantic search
- **Embeddings**: sentence-transformers for code representation
- **Few-Shot Learning**: Prompt engineering for domain adaptation
- **Semantic Search**: Finding similar code patterns via vector similarity
- **Multi-Modal Architecture**: Combining retrieval with generation
- **Database Design**: Efficient metadata storage and retrieval
- **System Integration**: Connecting multiple AI components

### Learning Objectives:

1. Understanding Large Language Models and their capabilities
2. Practical API integration with modern LLMs
3. Building user-friendly web interfaces for AI applications
4. Implementing RAG systems for enhanced AI performance ğŸ†•
5. Vector database design and optimization ğŸ†•
6. Domain-specific AI adaptation without fine-tuning ğŸ†•

---

- **AI Integration**: Practical use of LLMs in web applications
- **API Development**: RESTful API design with FastAPI
- **Async Programming**: Async/await patterns in Python
- **Web Development**: Frontend-backend communication
- **Error Handling**: Robust error handling and user feedback
- **Environment Management**: Secure configuration with environment variables

---

## ğŸš§ Future Enhancements (Phase 2+)

Potential features for future phases:

- ğŸ” Code quality analysis and bug detection
- âš¡ Performance optimization suggestions
- ğŸ”„ Code refactoring recommendations
- ğŸ” Security vulnerability identification
- ğŸ’¬ Interactive Q&A about code
- ğŸ“ Automatic documentation generation
- ğŸŒ Multi-file project analysis
- ğŸ‘¥ User authentication and history
- ğŸ“Š Usage analytics dashboard

---

## ğŸ¤ Contributing

This is a Phase 1 CS project. For educational purposes, the codebase is kept simple and well-commented. Feel free to:

- Report issues
- Suggest improvements
- Fork and experiment
- Use as a learning resource

---

## ğŸ“„ License

This project is created for educational purposes as part of a CS course assignment.

---

## ğŸ‘¨â€ğŸ’» Author

**Course**: Computer Science - AI/LLM Integration Project  
**Phase**: 1 - Core Functionality  
**Model**: LLaMA 3.3 70B Versatile (Meta AI via Groq)

---

## ğŸ™ Acknowledgments

- **Meta AI** for LLaMA 3.3 70B model
- **Groq** for fast, free inference infrastructure
- **FastAPI** for the excellent Python web framework
- The open-source community for inspiration and tools

---

## ğŸ“ Support

If you encounter issues:

1. Check the troubleshooting section above
2. Review the error messages carefully
3. Check the browser console (F12) for frontend errors
4. Check the terminal output for backend errors
5. Verify all prerequisites are met
6. Ensure your API key is valid and properly configured

---

**Ready to explain some code? Let's get started! ğŸš€**
